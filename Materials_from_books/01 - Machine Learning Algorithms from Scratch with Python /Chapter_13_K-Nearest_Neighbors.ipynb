{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Chapter 13 - K-Nearest Neighbors"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt\n",
    "from random import seed\n",
    "\n",
    "from Codes.ch01_load_and_convert_data import load_csv, str_column_to_float, str_column_to_int\n",
    "from Codes.ch02_scale_data_functions import dataset_minmax, normalize_dataset\n",
    "from Codes.ch06_algorithm_test_harnesses import evaluate_algorithm_kfold, evaluate_algorithm_kfold_reg"
   ]
  },
  {
   "source": [
    "### Euclidean Distance"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the Euclidian distance between two vectors\n",
    "def euclidean_distance(row1, row2):\n",
    "    distance = 0.0\n",
    "    for i in range(len(row1)-1):\n",
    "        distance += (row1[i] - row2[i])**2\n",
    "    return sqrt(distance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.0\n1.3290173915275787\n1.9494646655653247\n1.5591439385540549\n0.5356280721938492\n4.850940186986411\n2.592833759950511\n4.214227042632867\n6.522409988228337\n4.985585382449795\n"
     ]
    }
   ],
   "source": [
    "# Test distance function\n",
    "dataset = [[2.7810836,2.550537003,0],\n",
    "[1.465489372,2.362125076,0],\n",
    "[3.396561688,4.400293529,0],\n",
    "[1.38807019,1.850220317,0],\n",
    "[3.06407232,3.005305973,0],\n",
    "[7.627531214,2.759262235,1],\n",
    "[5.332441248,2.088626775,1],\n",
    "[6.922596716,1.77106367,1],\n",
    "[8.675418651,-0.242068655,1],\n",
    "[7.673756466,3.508563011,1]]\n",
    "row0 = dataset[0]\n",
    "for row in dataset:\n",
    "    distance = euclidean_distance(row0, row)\n",
    "    print(distance)"
   ]
  },
  {
   "source": [
    "### Get Neighbors"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Locate the most similar neighbors\n",
    "def get_neighbors(train, test_row, num_neighbors):\n",
    "    distances = list()\n",
    "    for train_row in train:\n",
    "        dist = euclidean_distance(test_row, train_row)\n",
    "        distances.append((train_row, dist))\n",
    "    distances.sort(key=lambda tup: tup[1])\n",
    "    neighbors = list()\n",
    "    for i in range(num_neighbors):\n",
    "        neighbors.append(distances[i][0])\n",
    "    return neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[2.7810836, 2.550537003, 0]\n[3.06407232, 3.005305973, 0]\n[1.465489372, 2.362125076, 0]\n"
     ]
    }
   ],
   "source": [
    "# Test get neighbors function\n",
    "dataset = [[2.7810836,2.550537003,0],\n",
    "[1.465489372,2.362125076,0],\n",
    "[3.396561688,4.400293529,0],\n",
    "[1.38807019,1.850220317,0],\n",
    "[3.06407232,3.005305973,0],\n",
    "[7.627531214,2.759262235,1],\n",
    "[5.332441248,2.088626775,1],\n",
    "[6.922596716,1.77106367,1],\n",
    "[8.675418651,-0.242068655,1],\n",
    "[7.673756466,3.508563011,1]]\n",
    "neighbors = get_neighbors(dataset, dataset[0], 3)\n",
    "for neighbor in neighbors:\n",
    "    print(neighbor)"
   ]
  },
  {
   "source": [
    "### Make Predictions\n",
    "\n",
    "#### Classification"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a classification prediction with neighbors\n",
    "def predict_classification(train, test_row, num_neighbors):\n",
    "    neighbors = get_neighbors(train, test_row, num_neighbors)\n",
    "    output_values = [row[-1] for row in neighbors]\n",
    "    prediction = max(set(output_values), key=output_values.count)\n",
    "    return prediction "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Expected 0, Got 0.\n"
     ]
    }
   ],
   "source": [
    "# Test predict classification function\n",
    "dataset = [[2.7810836,2.550537003,0],\n",
    "[1.465489372,2.362125076,0],\n",
    "[3.396561688,4.400293529,0],\n",
    "[1.38807019,1.850220317,0],\n",
    "[3.06407232,3.005305973,0],\n",
    "[7.627531214,2.759262235,1],\n",
    "[5.332441248,2.088626775,1],\n",
    "[6.922596716,1.77106367,1],\n",
    "[8.675418651,-0.242068655,1],\n",
    "[7.673756466,3.508563011,1]]\n",
    "prediction = predict_classification(dataset, dataset[0], 3)\n",
    "print('Expected %d, Got %d.' % (dataset[0][-1], prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make a regression predict with neighbors\n",
    "def predict_regression(train, test_row, num_neighbors):\n",
    "    neighbors = get_neighbors(train, test_row, num_neighbors)\n",
    "    output_values = [row[-1] for row in neighbors]\n",
    "    prediction = sum(output_values) / float(len(output_values))\n",
    "    return prediction"
   ]
  },
  {
   "source": [
    "### Abalone Case Study as Classification"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN algorithm \n",
    "def k_nearest_neighbors(train, test, num_neighbors):\n",
    "    predictions = list()\n",
    "    for row in test:\n",
    "        output = predict_classification(train, row, num_neighbors)\n",
    "        predictions.append(output)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Scores: [24.790419161676645, 21.79640718562874, 23.592814371257482, 21.676646706586826, 23.353293413173652]\nMean Accuracy: 23.042%\n"
     ]
    }
   ],
   "source": [
    "# Test the kNN on the Abalone dataset\n",
    "seed(1)\n",
    "\n",
    "# load and prepare data\n",
    "filename = './data/abalone.csv'\n",
    "dataset = load_csv(filename)\n",
    "for i in range(1, len(dataset[0])):\n",
    "    str_column_to_float(dataset, i)\n",
    "# convert first column to integers\n",
    "str_column_to_int(dataset, 0)\n",
    "\n",
    "# evaluate algorithm\n",
    "n_folds = 5\n",
    "num_neighbors = 5\n",
    "scores = evaluate_algorithm_kfold(dataset, k_nearest_neighbors, n_folds, num_neighbors)\n",
    "print('Scores: %s' % scores)\n",
    "print('Mean Accuracy: %.3f%%' % (sum(scores)/float(len(scores))))"
   ]
  },
  {
   "source": [
    "### Abalone Case Study as Regression"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# KNN algorithm \n",
    "def k_nearest_neighbors(train, test, num_neighbors):\n",
    "    predictions = list()\n",
    "    for row in test:\n",
    "        output = predict_regression(train, row, num_neighbors)\n",
    "        predictions.append(output)\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Scores: [2.170383116929243, 2.2087035241256405, 2.2321118594939215, 2.4013070293283603, 2.2274928845898017]\nMean Accuracy: 2.248%\n"
     ]
    }
   ],
   "source": [
    "# Test the kNN on the Abalone dataset\n",
    "seed(1)\n",
    "\n",
    "# load and prepare data\n",
    "filename = './data/abalone.csv'\n",
    "dataset = load_csv(filename)\n",
    "for i in range(1, len(dataset[0])):\n",
    "    str_column_to_float(dataset, i)\n",
    "# convert first column to integers\n",
    "str_column_to_int(dataset, 0)\n",
    "\n",
    "# evaluate algorithm\n",
    "n_folds = 5\n",
    "num_neighbors = 5\n",
    "scores = evaluate_algorithm_kfold_reg(dataset, k_nearest_neighbors, n_folds, num_neighbors)\n",
    "print('Scores: %s' % scores)\n",
    "print('Mean Accuracy: %.3f%%' % (sum(scores)/float(len(scores))))"
   ]
  },
  {
   "source": [
    "## Future Works\n",
    "\n",
    "* Tune KNN. Try larger and larger k values to see if you can improve the performance of the algorithm on the Abalone dataset.\n",
    "* Regression for Classification. Combine the approach used to make predictions for regression problems (take the mean) with the classification approach to making predictions (return an integer) and see if you can improve results.\n",
    "* More Distance Measures. Implement other distance measures that you can use to find similar historical data, such as Hamming distance, Manhattan distance and Minkowski distance.\n",
    "* Data Preparation. Distance measures are strongly affected by the scale of the input data. Experiment with normalization and standardization data preparation methods in order to improve results.\n",
    "* More Problems. As always, experiment with the technique on more and different classification and regression problems."
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}