{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chapter 02 - Scale Machine Learning Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modules\n",
    "from ch01_load_and_convert_data import  load_csv, str_column_to_float\n",
    "from math import sqrt"
   ]
  },
  {
   "source": [
    "### Normalize data\n",
    "\n",
    "* Normalization here refer to rescaling an input variable to the range between 0 and 1."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get min and max values for each column\n",
    "def dataset_minmax(dataset):\n",
    "    minmax = list()\n",
    "    for i in range(len(dataset[0])):\n",
    "        # Get the values of a specific column\n",
    "        col_values = [row[i] for row in dataset]\n",
    "        # Get the min value\n",
    "        value_min = min(col_values)\n",
    "        # Get the max value\n",
    "        value_max = max(col_values)\n",
    "        # Add them to a list\n",
    "        minmax.append([value_min, value_max])\n",
    "    return minmax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[50, 30], [20, 90]]\n[[20, 50], [30, 90]]\n"
     ]
    }
   ],
   "source": [
    "# Testing the function\n",
    "dataset = [[50, 30], [20, 90]]\n",
    "print(dataset)\n",
    "\n",
    "minmax = dataset_minmax(dataset)\n",
    "print(minmax)"
   ]
  },
  {
   "source": [
    "The calculation to normalize a single value for a column is:\n",
    "\n",
    "scaled value = $\\frac{value - min}{max - min}$"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rescale dataset columns to the range 0-1\n",
    "def normalize_dataset(dataset, minmax):\n",
    "    for row in dataset:\n",
    "        for i in range(len(row)):\n",
    "            row[i] = (row[i] - minmax[i][0]) / (minmax[i][1] - minmax[i][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[50, 30], [20, 90]]\n[[20, 50], [30, 90]]\n[[1.0, 0.0], [0.0, 1.0]]\n"
     ]
    }
   ],
   "source": [
    "# Testing the functions with a small dataset\n",
    "dataset = [[50, 30], [20, 90]]\n",
    "print(dataset)\n",
    "\n",
    "minmax = dataset_minmax(dataset)\n",
    "print(minmax)\n",
    "\n",
    "normalize_dataset(dataset, minmax)\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Loaded data file ./data/pima-indians-diabetes.csv with 768 rows and 9 columns\nBefore the normalization\n[6.0, 148.0, 72.0, 35.0, 0.0, 33.6, 0.627, 50.0, 1.0]\nAfter the normalization\n[0.35294117647058826, 0.7437185929648241, 0.5901639344262295, 0.35353535353535354, 0.0, 0.5007451564828614, 0.23441502988898377, 0.48333333333333334, 1.0]\n"
     ]
    }
   ],
   "source": [
    "# Normalizing the diabetes dataset\n",
    "filename = './data/pima-indians-diabetes.csv'\n",
    "dataset = load_csv(filename)\n",
    "\n",
    "# Visualizing the shape of the dataset\n",
    "print('Loaded data file {0} with {1} rows and {2} columns'.format(filename, len(dataset), len(dataset[0])))\n",
    "\n",
    "# Convert string columns to float\n",
    "for i in range(len(dataset[0])):\n",
    "    str_column_to_float(dataset, i)\n",
    "\n",
    "print(\"Before the normalization\")\n",
    "print(dataset[0])\n",
    "\n",
    "# Calculate the min and max for each column\n",
    "minmax = dataset_minmax(dataset)\n",
    "\n",
    "# Normalize columns\n",
    "nomalize_dataset(dataset, minmax)\n",
    "print(\"After the normalization\")\n",
    "print(dataset[0])"
   ]
  },
  {
   "source": [
    "### Standardize Data\n",
    "\n",
    "Standardization is a rescaling technique that refers to centering the distribution of the data on the value 0 and the stardard deviation to the value 1.\n",
    "\n",
    "* Mean and stardard deviation need to be know prior to scaling."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate column mean\n",
    "def column_means(dataset):\n",
    "    # Create a list to means\n",
    "    means = [0 for i in range(len(dataset[0]))]\n",
    "    # Iterate by each row in dataset, get the\n",
    "    # values of a column, calculate the \n",
    "    # mean and assign to a means' list. \n",
    "    for i in range(len(dataset[0])):\n",
    "        col_values = [row[i] for row in dataset]\n",
    "        means[i] = sum(col_values) / float(len(dataset))\n",
    "    return means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate columns standard deviations\n",
    "def column_stdevs(dataset, means):\n",
    "    # Create a list to stdevs\n",
    "    stdevs = [0 for i in range(len(dataset[0]))]\n",
    "    # Iterate by each row in dataset, get the\n",
    "    # values of a column, calculate the \n",
    "    # variance and the sum of variance and \n",
    "    # assign to a stdevs' list.\n",
    "    for i in range(len(dataset[0])):\n",
    "        variance = [pow(row[i] - means[i], 2) for row in dataset]\n",
    "        stdevs[i] = sum(variance)\n",
    "    # Calculate the sqrt of sum of variances divided by\n",
    "    # the number of rows minus 1\n",
    "    stdevs = [sqrt(x/(float(len(dataset)-1))) for x in stdevs] \n",
    "    return stdevs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[50, 30], [20, 90], [30, 50]]\n[33.333333333333336, 56.666666666666664]\n[15.275252316519467, 30.550504633038933]\n"
     ]
    }
   ],
   "source": [
    "# Testing the functions with a small dataset\n",
    "dataset = [[50, 30], [20, 90], [30, 50]]\n",
    "print(dataset)\n",
    "\n",
    "means = column_means(dataset)\n",
    "stdevs = column_stdevs(dataset, means)\n",
    "\n",
    "print(means)\n",
    "print(stdevs)"
   ]
  },
  {
   "source": [
    "The calculation to stardardize a given value is as follow:\n",
    "\n",
    "$standardized-value_i = \\frac{value_i - mean}{stdev}$"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardize dataset\n",
    "def standardize_dataset(dataset, means, stdevs):\n",
    "    # Iterate by each value in a dataset and calculate\n",
    "    # a new value. \n",
    "    for row in dataset:\n",
    "        for i in range(len(row)):\n",
    "            row[i] = (row[i] - means[i]) / stdevs[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[50, 30], [20, 90], [30, 50]]\n[33.333333333333336, 56.666666666666664]\n[15.275252316519467, 30.550504633038933]\n[[1.0910894511799618, -0.8728715609439694], [-0.8728715609439697, 1.091089451179962], [-0.21821789023599253, -0.2182178902359923]]\n"
     ]
    }
   ],
   "source": [
    "# Testing the functions with a small dataset\n",
    "dataset = [[50, 30], [20, 90], [30, 50]]\n",
    "print(dataset)\n",
    "\n",
    "# Estimate mean and standard deviation\n",
    "means = column_means(dataset)\n",
    "stdevs = column_stdevs(dataset, means)\n",
    "print(means)\n",
    "print(stdevs)\n",
    "\n",
    "# Standardize dataset\n",
    "standardize_dataset(dataset, means, stdevs)\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Loaded data file ./data/pima-indians-diabetes.csv with 768 rows and 9 columns\nBefore the normalization\n[6.0, 148.0, 72.0, 35.0, 0.0, 33.6, 0.627, 50.0, 1.0]\n[0.6395304921176576, 0.8477713205896718, 0.14954329852954296, 0.9066790623472505, -0.692439324724129, 0.2038799072674717, 0.468186870229798, 1.4250667195933604, 1.3650063669598067]\n"
     ]
    }
   ],
   "source": [
    "# Standardize the diabetes dataset\n",
    "filename = './data/pima-indians-diabetes.csv'\n",
    "dataset = load_csv(filename)\n",
    "\n",
    "# Visualizing the shape of the dataset\n",
    "print('Loaded data file {0} with {1} rows and {2} columns'.format(filename, len(dataset), len(dataset[0])))\n",
    "\n",
    "# Convert string columns to float\n",
    "for i in range(len(dataset[0])):\n",
    "    str_column_to_float(dataset, i)\n",
    "\n",
    "print(\"Before the normalization\")\n",
    "print(dataset[0])\n",
    "\n",
    "# Estimate mean and standard deviation\n",
    "means = column_means(dataset)\n",
    "stdevs = column_stdevs(dataset, means)\n",
    "\n",
    "# Standardize dataset\n",
    "standardize_dataset(dataset, means, stdevs)\n",
    "print(dataset[0])"
   ]
  },
  {
   "source": [
    "### When to Normalize and Standardize\n",
    "\n",
    "* Standardization assumes the our data is in normal distribution or close to normal. In that case, in wich our data has this characteristic, standardization is the best method. \n",
    "* If our data is not normally distributed, normalization is the best method."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Future works\n",
    "\n",
    "To researching and implementing:\n",
    "\n",
    "* Normalization that permits a configurable range, such as -1 to 1 and more.\n",
    "* Standardization that permits a configurable spread, such as 1, 2 or more standard deviations\n",
    "from the mean.\n",
    "* Exponential transforms such as logarithm, square root and exponents.\n",
    "* Power transforms such as Box-Cox for fixing the skew in normally distributed data."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}