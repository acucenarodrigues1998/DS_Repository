{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Chapter 06 - Algorithm Test Harnesses\n",
    "\n",
    "A test harness provides a consistent way to evaluate machine learning algorithms on a dataset. It involves 3 elements:\n",
    "\n",
    "1. The resampling method to split-up the dataset.\n",
    "2. The machine learning algorithm to evaluate.\n",
    "3. The performance measure by which to evaluate predictions."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import seed\n",
    "from Codes.ch01_load_and_convert_data import load_csv, str_column_to_float\n",
    "from Codes.ch03_resampling_methods import train_test_split, cross_validation_split\n",
    "from Codes.ch04_evaluation_metrics import accuracy_metric\n",
    "from Codes.ch05_baseline_models import zero_rule_algorithm_classification"
   ]
  },
  {
   "source": [
    "### Train-Test Algorithm Test Harness"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate an algorithm using a train/test split\n",
    "def evaluate_algorithm_train_test(dataset, algorithm, split, *args):\n",
    "    train, test = train_test_split(dataset, split)\n",
    "    test_set = list()\n",
    "    for row in test:\n",
    "        row_copy = list(row)\n",
    "        row_copy[-1] = None\n",
    "        test_set.append(row_copy)\n",
    "    predicted = algorithm(train, test_set, *args)\n",
    "    actual = [row[-1] for row in test]\n",
    "    accuracy = accuracy_metric(actual, predicted)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy: 67.427%\n"
     ]
    }
   ],
   "source": [
    "# Test the train/test harness \n",
    "seed(1)\n",
    "\n",
    "# Load and prepare data\n",
    "filename = './data/pima-indians-diabetes.csv'\n",
    "dataset = load_csv(filename)\n",
    "for i in range(len(dataset[0])):\n",
    "    str_column_to_float(dataset, i)\n",
    "\n",
    "# evaluate algorithm\n",
    "split = 0.6\n",
    "accuracy = evaluate_algorithm_train_test(dataset, zero_rule_algorithm_classification, split)\n",
    "print('Accuracy: %.3f%%' % (accuracy))"
   ]
  },
  {
   "source": [
    "### Cross-Validation Algorithm Test Harness"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_algorithm_kfold(dataset, algorithm, n_folds, *args):\n",
    "    folds = cross_validation_split(dataset, n_folds)\n",
    "    scores = list()\n",
    "    for fold in folds:\n",
    "        train_set = list(folds)\n",
    "        train_set.remove(fold)\n",
    "        train_set = sum(train_set, [])\n",
    "        test_set = list()\n",
    "        for row in fold:\n",
    "            row_copy = list(row)\n",
    "            test_set.append(row_copy)\n",
    "            row_copy[-1] = None\n",
    "        predicted = algorithm(train_set, test_set, *args)\n",
    "        actual = [row[-1] for row in fold]\n",
    "        accuracy = accuracy_metric(actual, predicted)\n",
    "        scores.append(accuracy)\n",
    "    return scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Scores: [62.091503267973856, 64.70588235294117, 64.70588235294117, 64.70588235294117, 69.28104575163398]\nMean Accuracy: 65.098%\n"
     ]
    }
   ],
   "source": [
    "# Test the train/test harness \n",
    "seed(1)\n",
    "\n",
    "# Load and prepare data\n",
    "filename = './data/pima-indians-diabetes.csv'\n",
    "dataset = load_csv(filename)\n",
    "for i in range(len(dataset[0])):\n",
    "    str_column_to_float(dataset, i)\n",
    "\n",
    "# Evaluate Algorithm\n",
    "n_folds = 5\n",
    "scores = evaluate_algorithm_kfold(dataset, zero_rule_algorithm_classification, n_folds)\n",
    "print( 'Scores: %s' % scores)\n",
    "print( 'Mean Accuracy: %.3f%%' % (sum(scores)/len(scores)))"
   ]
  },
  {
   "source": [
    "## Future Works\n",
    "\n",
    "* Parameterized Evaluation. Pass in the function used to evaluate predictions, allowing\n",
    "you to seamlessly work with regression problems.\n",
    "* Parameterized Resampling. Pass in the function used to calculate resampling splits,\n",
    "allowing you to easily switch between the train-test and cross-validation methods.\n",
    "* Standard Deviation Scores. Calculate the standard deviation to get an idea of the\n",
    "spread of scores when evaluating algorithms using cross-validation."
   ],
   "cell_type": "markdown",
   "metadata": {}
  }
 ]
}