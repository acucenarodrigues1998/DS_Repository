{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Chapter 12 - Naive Bayes\n",
    "\n",
    "### Separate by class"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from math import sqrt, exp, pi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the dataset by class values, returns a dictionary\n",
    "def separate_by_class(dataset):\n",
    "    separated = dict()\n",
    "    for i in range(len(dataset)):\n",
    "        vector = dataset[i]\n",
    "        class_value = vector[-1]\n",
    "        if (class_value not in separated):\n",
    "            separated[class_value] = list()\n",
    "        separated[class_value].append(vector)\n",
    "    return separated "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0\n[3.393533211, 2.331273381, 0]\n[3.110073483, 1.781539638, 0]\n[1.343808831, 3.368360954, 0]\n[3.582294042, 4.67917911, 0]\n[2.280362439, 2.866990263, 0]\n1\n[7.423436942, 4.696522875, 1]\n[5.745051997, 3.533989803, 1]\n[9.172168622, 2.511101045, 1]\n[7.792783481, 3.424088941, 1]\n[7.939820817, 0.791637231, 1]\n"
     ]
    }
   ],
   "source": [
    "dataset = [[3.393533211,2.331273381,0],\n",
    "[3.110073483,1.781539638,0],\n",
    "[1.343808831,3.368360954,0],\n",
    "[3.582294042,4.67917911,0],\n",
    "[2.280362439,2.866990263,0],\n",
    "[7.423436942,4.696522875,1],\n",
    "[5.745051997,3.533989803,1],\n",
    "[9.172168622,2.511101045,1],\n",
    "[7.792783481,3.424088941,1],\n",
    "[7.939820817,0.791637231,1]]\n",
    "\n",
    "separated = separate_by_class(dataset)\n",
    "\n",
    "for label in separated:\n",
    "    print(label)\n",
    "    for row in separated[label]:\n",
    "        print(row)"
   ]
  },
  {
   "source": [
    "### Summarize Dataset"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mean of a list of numbers\n",
    "def mean(numbers):\n",
    "    return sum(numbers)/float(len(numbers))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the standard deviation of a list of numbers\n",
    "def stdev(numbers):\n",
    "    avg = mean(numbers)\n",
    "    variance = sum([(x-avg)**2 for x in numbers]) / float(len(numbers)-1)\n",
    "    return sqrt(variance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the mean, stdev and count for each column in a dataset\n",
    "def summarize_dataset(dataset):\n",
    "    summaries = [(mean(column), stdev(column), len(column)) for column in zip(*dataset)]\n",
    "    del(summaries[-1])\n",
    "    return summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[(5.178333386499999, 2.7665845055177263, 10), (2.9984683241, 1.218556343617447, 10)]\n"
     ]
    }
   ],
   "source": [
    "# Test summarizing a dataset\n",
    "dataset = [[3.393533211,2.331273381,0],\n",
    "[3.110073483,1.781539638,0],\n",
    "[1.343808831,3.368360954,0],\n",
    "[3.582294042,4.67917911,0],\n",
    "[2.280362439,2.866990263,0],\n",
    "[7.423436942,4.696522875,1],\n",
    "[5.745051997,3.533989803,1],\n",
    "[9.172168622,2.511101045,1],\n",
    "[7.792783481,3.424088941,1],\n",
    "[7.939820817,0.791637231,1]]\n",
    "summary = summarize_dataset(dataset)\n",
    "print(summary)"
   ]
  },
  {
   "source": [
    "### Summarize Data By Class"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split dataset by class then calculate statisticas for each row\n",
    "def summarize_by_class(dataset):\n",
    "    separated = separate_by_class(dataset)\n",
    "    summaries = dict()\n",
    "    for class_value, rows in separated.items():\n",
    "        summaries[class_value] = summarize_dataset(rows)\n",
    "    return summaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0\n(2.7420144012, 0.9265683289298018, 5)\n(3.0054686692, 1.1073295894898725, 5)\n1\n(7.6146523718, 1.2344321550313704, 5)\n(2.9914679790000003, 1.4541931384601618, 5)\n"
     ]
    }
   ],
   "source": [
    "# Test summarizing by class\n",
    "dataset = [[3.393533211,2.331273381,0],\n",
    "[3.110073483,1.781539638,0],\n",
    "[1.343808831,3.368360954,0],\n",
    "[3.582294042,4.67917911,0],\n",
    "[2.280362439,2.866990263,0],\n",
    "[7.423436942,4.696522875,1],\n",
    "[5.745051997,3.533989803,1],\n",
    "[9.172168622,2.511101045,1],\n",
    "[7.792783481,3.424088941,1],\n",
    "[7.939820817,0.791637231,1]]\n",
    "summary = summarize_by_class(dataset)\n",
    "for label in summary:\n",
    "    print(label)\n",
    "    for row in summary[label]:\n",
    "        print(row)"
   ]
  },
  {
   "source": [
    "### Gaussian Probability Density Function"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the Gaussian probability distribution function for x\n",
    "def calculate_probability(x, mean, stdev):\n",
    "    exponent = exp(-((x-mean)**2 / (2 * stdev**2))) \n",
    "    return (1 / (sqrt(2 * pi) * stdev)) * exponent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "0.3989422804014327\n0.24197072451914337\n0.24197072451914337\n"
     ]
    }
   ],
   "source": [
    "# Test Gaussian PDF\n",
    "print(calculate_probability(1.0, 1.0, 1.0))\n",
    "print(calculate_probability(2.0, 1.0, 1.0))\n",
    "print(calculate_probability(0.0, 1.0, 1.0))"
   ]
  },
  {
   "source": [
    "### Class Probabilities"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the probabilities of predicting each class for a given row\n",
    "def calculate_class_probabilities(summaries, row):\n",
    "    total_rows = sum([summaries[label][0][2] for label in summaries])\n",
    "    probabilities = dict()\n",
    "    for class_value, class_summaries in summaries.items():\n",
    "        probabilities[class_value] = summaries[class_value][0][2]/float(total_rows)\n",
    "        for i in range(len(class_summaries)):\n",
    "            mean, stdev, _ = class_summaries[i]\n",
    "            probabilities[class_value] *= calculate_probability(row[i], mean, stdev)\n",
    "    return probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "{0: 0.05032427673372076, 1: 0.00011557718379945765}\n"
     ]
    }
   ],
   "source": [
    "# Test calculating class probabilities\n",
    "dataset = [[3.393533211,2.331273381,0],\n",
    "[3.110073483,1.781539638,0],\n",
    "[1.343808831,3.368360954,0],\n",
    "[3.582294042,4.67917911,0],\n",
    "[2.280362439,2.866990263,0],\n",
    "[7.423436942,4.696522875,1],\n",
    "[5.745051997,3.533989803,1],\n",
    "[9.172168622,2.511101045,1],\n",
    "[7.792783481,3.424088941,1],\n",
    "[7.939820817,0.791637231,1]]\n",
    "summaries = summarize_by_class(dataset)\n",
    "probabilities = calculate_class_probabilities(summaries, dataset[0])\n",
    "print(probabilities)"
   ]
  },
  {
   "source": [
    "### Iris Flower Species Case Study"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Codes.ch01_load_and_convert_data import load_csv, str_column_to_float, str_column_to_int\n",
    "from Codes.ch06_algorithm_test_harnesses import evaluate_algorithm_kfold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict the class for a given row\n",
    "def predict(summaries, row):\n",
    "    probabilities = calculate_class_probabilities(summaries, row)\n",
    "    best_label, best_prob = None, -1\n",
    "    for class_value, probability in probabilities.items():\n",
    "        if best_label is None or probability > best_prob:\n",
    "            best_prob = probability\n",
    "            best_label = class_value \n",
    "    return best_label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Naive Bayes Algorithm\n",
    "def naive_bayes(train, test):\n",
    "    summarize = summarize_by_class(train)\n",
    "    predictions = list()\n",
    "    for row in test:\n",
    "        output = predict(summarize, row)\n",
    "        predictions.append(output)\n",
    "    return (predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Scores: [96.66666666666667, 100.0, 96.66666666666667, 90.0, 90.0]\nMean Accuracy: 94.667%\n"
     ]
    }
   ],
   "source": [
    "# Test Naive Bayes on Iris Dataset\n",
    "filename = './data/iris.csv'\n",
    "dataset = load_csv(filename)\n",
    "for i in range(len(dataset[0])-1):\n",
    "    str_column_to_float(dataset, i)\n",
    "# convert class column to integers\n",
    "str_column_to_int(dataset, len(dataset[0])-1)\n",
    "# evaluate algorithm\n",
    "n_folds = 5\n",
    "scores = evaluate_algorithm_kfold(dataset, naive_bayes, n_folds)\n",
    "print('Scores: %s' % scores)\n",
    "print('Mean Accuracy: %.3f%%' % (sum(scores)/float(len(scores))))"
   ]
  },
  {
   "source": [
    "## Future Works\n",
    "\n",
    "* Categorical Input Variables. Only real-valued inputs were supported in the tutorial. Update it to support categorical input values by calculating the probability as their frequency ratio.\n",
    "* Log Probabilities. Probabilities become very small numbers in Naive Bayes because they are multiplied together. This can cause problems on datasets with more input features. Converting all probabilities to log values (e.g. p = log(1 + p)) before they are multiplied together can remedy this problem."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}