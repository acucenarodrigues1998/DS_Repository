{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Chapter 03 - Algorithm Evaluation Methods"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import seed, randrange"
   ]
  },
  {
   "source": [
    "### Train and Test Split\n",
    "\n",
    "This method consists in split the dataset into two parts:\n",
    "\n",
    "* Training dataset\n",
    "* Test dataset\n",
    "\n",
    "The training dataset is used by the machine learning algorithm to train the model. The test dataset is used to evaluate the performance of the model. \n",
    "\n",
    "The rows assigned to each dataset are randomly selected.\n",
    "\n",
    "If multiples algorithms or multiple configurations of the same algorithm are compared, the same train and test split of the dataset should be used."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split a dataset into a train and test set\n",
    "def train_test_split(dataset, split=0.6):\n",
    "    train = list()\n",
    "    # Calculates how many rows the training set \n",
    "    # requires from the provided dataset.\n",
    "    train_size = split * len(dataset)\n",
    "    # Make a copy of the original dataset\n",
    "    dataset_copy = list(dataset)\n",
    "    # Random rows are selected and removed from\n",
    "    # the copied dataset and added to the train\n",
    "    # dataset.\n",
    "    while len(train) < train_size:\n",
    "        index = randrange(len(dataset_copy))\n",
    "        train.append(dataset_copy.pop(index))\n",
    "    return train, dataset_copy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[3], [2], [7], [1], [8], [9]]\n[[4], [5], [6], [10]]\n"
     ]
    }
   ],
   "source": [
    "# Test train/test split\n",
    "seed(1)\n",
    "dataset = [[1], [2], [3], [4], [5], \n",
    "[6], [7], [8], [9], [10]]\n",
    "train, test = train_test_split(dataset)\n",
    "print(train)\n",
    "print(test)"
   ]
  },
  {
   "source": [
    "### K-fold Cross-Validation Split\n",
    "\n",
    "The K-Fold cross-validation method (also called just cross-validation) is a resampling method that provides a more accurate estimate of algorithm performance. \n",
    "\n",
    "The data is divided in k groups (folds) and the algorithm is trained and evaluated k times and the performance is the mean performance score.\n",
    "\n",
    "First the algorithm was training with k-1 groups and evaluated with the kth group. This is repeated so that each of the k groups is given an opportunity to be held out and used as the test set. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split a dataset into k folds\n",
    "def cross_validation_split(dataset, folds=3):\n",
    "    dataset_split = list()\n",
    "    dataset_copy = list(dataset)\n",
    "    # Calculate the size of each fold\n",
    "    fold_size = int(len(dataset)/folds)\n",
    "    for _ in range(folds):\n",
    "        fold = list()\n",
    "        # Its the same process that the \n",
    "        # train_test_split. Remove a row \n",
    "        # from the dataset_copy and add \n",
    "        # to a fold.  \n",
    "        while len(fold) < fold_size:\n",
    "            index = randrange(len(dataset_copy))\n",
    "            fold.append(dataset_copy.pop(index))\n",
    "        dataset_split.append(fold)\n",
    "    return dataset_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[[3], [2], [7]], [[1], [8], [9]], [[10], [6], [5]]]\n"
     ]
    }
   ],
   "source": [
    "# Test cross validation split\n",
    "seed(1)\n",
    "dataset = [[1], [2], [3], [4], [5], \n",
    "[6], [7], [8], [9], [10]]\n",
    "folds = cross_validation_split(dataset)\n",
    "print(folds)"
   ]
  }
 ]
}